import requests
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

def get_final_url(url, max_redirects=5, timeout=5):
    """
    è·å– URL çš„æœ€ç»ˆé‡å®šå‘åœ°å€ï¼ˆæ”¯æŒå¤šçº¿ç¨‹ï¼‰
    :param url: åŸå§‹ URL
    :param max_redirects: æœ€å¤§é‡å®šå‘æ¬¡æ•°
    :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :return: æœ€ç»ˆ URLï¼ˆå¦‚æœå¤±è´¥åˆ™è¿”å›åŸå§‹ URLï¼‰
    """
    try:
        response = requests.get(url, allow_redirects=False, timeout=timeout)
        redirect_count = 0
        
        while redirect_count < max_redirects:
            if response.status_code in (301, 302, 303, 307, 308) and 'Location' in response.headers:
                new_url = response.headers['Location']
                # å¤„ç†ç›¸å¯¹è·¯å¾„é‡å®šå‘ï¼ˆå¦‚ Location: /new-pathï¼‰
                if not new_url.startswith(('http://', 'https://')):
                    from urllib.parse import urljoin
                    new_url = urljoin(url, new_url)
                url = new_url
                response = requests.get(url, allow_redirects=False, timeout=timeout)
                redirect_count += 1
            else:
                break
        
        return url
    except requests.RequestException as e:
        print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {url} ({type(e).__name__}: {e})")
        return url  # å¤±è´¥æ—¶è¿”å›åŸ URL

def process_m3u_file(input_file, output_file, max_workers=10, timeout=5):
    """
    å¤„ç† M3U æ–‡ä»¶ï¼ˆå¤šçº¿ç¨‹ä¼˜åŒ–ç‰ˆï¼‰
    :param input_file: è¾“å…¥ M3U æ–‡ä»¶è·¯å¾„
    :param output_file: è¾“å‡º M3U æ–‡ä»¶è·¯å¾„
    :param max_workers: çº¿ç¨‹æ± å¤§å°
    :param timeout: å•ä¸ª URL è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    """
    start_time = time.time()
    
    # è¯»å–åŸå§‹æ–‡ä»¶
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = [line.strip() for line in f.readlines()]

    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåŒ¹é… URL è¡Œï¼‰
    url_pattern = re.compile(r'^https?://\S+')

    # å¤šçº¿ç¨‹å¤„ç†æ‰€æœ‰ URL
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {}
        for i, line in enumerate(lines):
            if url_pattern.match(line):
                future = executor.submit(get_final_url, line, 10, timeout)
                futures[future] = i  # è®°å½•è¡Œå·

        # æŒ‰å®Œæˆé¡ºåºæ›´æ–°ç»“æœ
        for future in as_completed(futures):
            line_num = futures[future]
            final_url = future.result()
            lines[line_num] = final_url
            print(f"âœ… å¤„ç†å®Œæˆ: {lines[line_num]}")

    # å†™å…¥æ–°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼è€—æ—¶ {time.time() - start_time:.2f} ç§’")
    print(f"åŸå§‹æ–‡ä»¶: {input_file} â†’ è¾“å‡ºæ–‡ä»¶: {output_file}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    input_m3u = "migu.m3u"    # è¾“å…¥æ–‡ä»¶è·¯å¾„
    output_m3u = "final.m3u"      # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    process_m3u_file(input_m3u, output_m3u, max_workers=2, timeout=10)
