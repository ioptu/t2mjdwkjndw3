import requests
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import threading
from urllib.parse import urljoin

# é™é€Ÿé…ç½®
lock = threading.Lock()
request_timestamps = []
REQUESTS_PER_SECOND = 5  # æ¯ç§’æœ€å¤šè¯·æ±‚æ•°

def rate_limited():
    """æ§åˆ¶è¯·æ±‚é€Ÿç‡ï¼Œé¿å…è¿‡å¿«è®¿é—®ç›®æ ‡ç½‘ç«™"""
    with lock:
        now = time.time()
        while request_timestamps and now - request_timestamps[0] > 1:
            request_timestamps.pop(0)
        if len(request_timestamps) >= REQUESTS_PER_SECOND:
            wait_time = 1 - (now - request_timestamps[0])
            time.sleep(wait_time)
        request_timestamps.append(time.time())

def get_final_url(url, max_redirects=10, timeout=5, retries=3, retry_delay=1):
    """
    è·å– URL çš„æœ€ç»ˆé‡å®šå‘åœ°å€ï¼Œæ”¯æŒå¤±è´¥é‡è¯•ä¸èŠ‚æµ
    """
    for attempt in range(1, retries + 1):
        try:
            rate_limited()
            response = requests.get(url, allow_redirects=False, timeout=timeout)
            redirect_count = 0

            while redirect_count < max_redirects:
                if response.status_code in (301, 302, 303, 307, 308) and 'Location' in response.headers:
                    new_url = response.headers['Location']
                    if not new_url.startswith(('http://', 'https://')):
                        new_url = urljoin(url, new_url)
                    url = new_url
                    rate_limited()
                    response = requests.get(url, allow_redirects=False, timeout=timeout)
                    redirect_count += 1
                else:
                    break
            return url

        except requests.RequestException as e:
            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡è¯·æ±‚å¤±è´¥: {url} ({type(e).__name__}: {e})")
            if attempt < retries:
                time.sleep(retry_delay)
            else:
                return url  # æœ€åä¸€æ¬¡å¤±è´¥ï¼Œè¿”å›åŸå§‹ URL

def process_m3u_file(input_file, output_file, max_workers=10, timeout=5, retries=3, retry_delay=1):
    """
    å¤šçº¿ç¨‹å¤„ç† M3U æ–‡ä»¶ï¼Œæ”¯æŒé™é€Ÿä¸é‡è¯•
    """
    start_time = time.time()

    with open(input_file, 'r', encoding='utf-8') as f:
        lines = [line.strip() for line in f.readlines()]

    url_pattern = re.compile(r'^https?://\S+')

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {}
        for i, line in enumerate(lines):
            if url_pattern.match(line):
                future = executor.submit(get_final_url, line, 10, timeout, retries, retry_delay)
                futures[future] = i

        for future in as_completed(futures):
            line_num = futures[future]
            final_url = future.result()
            lines[line_num] = final_url
            print(f"âœ… å¤„ç†å®Œæˆ: {final_url}")

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼è€—æ—¶ {time.time() - start_time:.2f} ç§’")
    print(f"åŸå§‹æ–‡ä»¶: {input_file} â†’ è¾“å‡ºæ–‡ä»¶: {output_file}")

if __name__ == "__main__":
    input_m3u = "migu.m3u"
    output_m3u = "final.m3u"
    process_m3u_file(input_m3u, output_m3u,
                     max_workers=5,
                     timeout=10,
                     retries=3,
                     retry_delay=1)  # è®¾ç½®æ¯æ¬¡é‡è¯•é—´éš” 2 ç§’
